{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDnc5cqHPgAB"
   },
   "source": [
    "# Getting started with Captum Insights\n",
    "\n",
    "This notebook will walk you through the process of analysing your model using Captum Insights\n",
    "\n",
    "<table align=\"left\"><td>\n",
    "  <a target=\"_blank\"  href=\"https://colab.research.google.com/github/TannerGilbert/Interpreting-PyTorch-models-with-Captum/blob/master/Getting_started_with_Captum_Insights.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab\n",
    "  </a>\n",
    "</td><td>\n",
    "  <a target=\"_blank\"  href=\"https://github.com/TannerGilbert/Interpreting-PyTorch-models-with-Captum/blob/master/Getting_started_with_Captum_Insights.ipynb\">\n",
    "    <img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "</td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5TWSrgDQBw8"
   },
   "source": [
    "## Install Captum\n",
    "\n",
    "Installing Captum is super simple. All you need is a simple pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "07ssUUq7QD1v",
    "outputId": "19710b90-dbb4-453f-cd5d-25aebfd95962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting captum\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a2/fe37944a50633ffc048918ec0d1e9aafb6ad1e189deb09caae4a6270f2e6/captum-0.1.0-py3-none-any.whl (532kB)\n",
      "\r",
      "\u001b[K     |▋                               | 10kB 29.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 20kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 30kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 40kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 51kB 3.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 61kB 4.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 71kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 81kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 92kB 6.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 102kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 112kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 122kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 133kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 143kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 153kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 163kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 174kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 184kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 194kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 204kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 215kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 225kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 235kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 245kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 256kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 266kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 276kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 286kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 296kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 307kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 317kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 327kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 337kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 348kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 358kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 368kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 378kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 389kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 399kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 409kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 419kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 430kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 440kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 450kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 460kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 471kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 481kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 491kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 501kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 512kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 522kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 532kB 4.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from captum) (1.17.3)\n",
      "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.6/dist-packages (from captum) (1.3.1+cu100)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from captum) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.6.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->captum) (2.4.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->captum) (41.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->captum) (1.12.0)\n",
      "Installing collected packages: captum\n",
      "Successfully installed captum-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "waFzEeLyQFLI"
   },
   "source": [
    "## Getting started\n",
    "\n",
    "Before we can use Captum Insights we need to get a model. For this notebook I choose to train a simple CNN on the Captum data-set. If you are only interested in working with Google Colab you can skip this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LwicxiOPPgpz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "from captum.insights import AttributionVisualizer, Batch\n",
    "from captum.insights.features import ImageFeature\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RskH9EiaQWTR"
   },
   "source": [
    "Load pre-trained Resnet model and set it to eval mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "fGTSs_sTP-0H",
    "outputId": "a51988c4-d358-4d55-f551-2ad81ed532f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170500096it [00:04, 38718823.43it/s]                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "6MZbtI6KQjJc",
    "outputId": "cfe827b7-c8b1-49d2-8f0e-73197eb09bc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (relu2): ReLU()\n",
       "  (relu3): ReLU()\n",
       "  (relu4): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tzcWKUJKRlpD"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "cDruHimIRmkz",
    "outputId": "af07b2c0-e89b-40a8-e111-71a180132e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.212\n",
      "[1,  4000] loss: 1.877\n",
      "[1,  6000] loss: 1.690\n",
      "[1,  8000] loss: 1.594\n",
      "[1, 10000] loss: 1.538\n",
      "[1, 12000] loss: 1.512\n",
      "[2,  2000] loss: 1.429\n",
      "[2,  4000] loss: 1.401\n",
      "[2,  6000] loss: 1.367\n",
      "[2,  8000] loss: 1.336\n",
      "[2, 10000] loss: 1.341\n",
      "[2, 12000] loss: 1.328\n",
      "[3,  2000] loss: 1.244\n",
      "[3,  4000] loss: 1.243\n",
      "[3,  6000] loss: 1.227\n",
      "[3,  8000] loss: 1.228\n",
      "[3, 10000] loss: 1.182\n",
      "[3, 12000] loss: 1.208\n",
      "[4,  2000] loss: 1.141\n",
      "[4,  4000] loss: 1.134\n",
      "[4,  6000] loss: 1.125\n",
      "[4,  8000] loss: 1.129\n",
      "[4, 10000] loss: 1.121\n",
      "[4, 12000] loss: 1.097\n",
      "[5,  2000] loss: 1.043\n",
      "[5,  4000] loss: 1.032\n",
      "[5,  6000] loss: 1.048\n",
      "[5,  8000] loss: 1.067\n",
      "[5, 10000] loss: 1.061\n",
      "[5, 12000] loss: 1.062\n",
      "[6,  2000] loss: 0.955\n",
      "[6,  4000] loss: 0.974\n",
      "[6,  6000] loss: 1.012\n",
      "[6,  8000] loss: 1.008\n",
      "[6, 10000] loss: 1.047\n",
      "[6, 12000] loss: 0.991\n",
      "[7,  2000] loss: 0.920\n",
      "[7,  4000] loss: 0.926\n",
      "[7,  6000] loss: 0.962\n",
      "[7,  8000] loss: 0.951\n",
      "[7, 10000] loss: 0.960\n",
      "[7, 12000] loss: 0.954\n",
      "[8,  2000] loss: 0.882\n",
      "[8,  4000] loss: 0.904\n",
      "[8,  6000] loss: 0.907\n",
      "[8,  8000] loss: 0.911\n",
      "[8, 10000] loss: 0.936\n",
      "[8, 12000] loss: 0.929\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.cuda())\n",
    "        loss = criterion(outputs, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "qJ_fWR92SG14",
    "outputId": "0791fd7d-f52f-4dcb-8b5c-5e79b5ec6fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 60 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images.cuda())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.cuda()).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcDaVbhlSPmn"
   },
   "source": [
    "## Use Captum Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TD_lCSf1ST_K"
   },
   "outputs": [],
   "source": [
    "def baseline_func(input):\n",
    "    return input * 0\n",
    "\n",
    "def formatted_data_iter():\n",
    "    dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    dataloader = iter(\n",
    "        torch.utils.data.DataLoader(dataset, batch_size=4, shuffle=False, num_workers=2)\n",
    "    )\n",
    "    while True:\n",
    "        images, labels = next(dataloader)\n",
    "        yield Batch(inputs=images, labels=labels)\n",
    "\n",
    "visualizer = AttributionVisualizer(\n",
    "    models=[net],\n",
    "    score_func=lambda o: torch.nn.functional.softmax(o, 1),\n",
    "    classes=classes,\n",
    "    features=[\n",
    "        ImageFeature(\n",
    "            \"Photo\",\n",
    "            baseline_transforms=[baseline_func],\n",
    "            input_transforms=[transform],\n",
    "        )\n",
    "    ],\n",
    "    dataset=formatted_data_iter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "colab_type": "code",
    "id": "BqykFNA3TH8D",
    "outputId": "d5c979bd-bc95-4e8f-8b6d-380ccbfdd779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fetch data and view Captum Insights at http://localhost:60101/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"500px\"\n",
       "            src=\"http://127.0.0.1:60101\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f946bc57438>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer.render(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "v50-BAT3TKyd",
    "outputId": "5648a59a-3957-4d5d-a27e-d271db25c107"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-96214a478166>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'img/captum_insights.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0municode_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'img/captum_insights.png'"
     ]
    }
   ],
   "source": [
    "# show a screenshot if using notebook non-interactively\n",
    "from IPython.display import Image\n",
    "Image(filename='img/captum_insights.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Getting started with Captum Insights.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
